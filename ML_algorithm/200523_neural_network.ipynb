{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"200523_neural_network.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP/QHZXEtxA/goyYOlxYUAN"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"BQxMk46ex_pJ","colab_type":"text"},"source":["# 2020.05.23 머신러닝 알고리즘 스터디\n","# Neural Network (NN), Artificial Neural Network (ANN)\n","# 신경망, 인공신경망"]},{"cell_type":"markdown","metadata":{"id":"t8iBQ-LTyAji","colab_type":"text"},"source":["## Connect to Google Drive"]},{"cell_type":"code","metadata":{"id":"Be4uFd92yLSz","colab_type":"code","outputId":"55b41f32-0e5f-450f-e500-96c430596a8e","executionInfo":{"status":"ok","timestamp":1589695545190,"user_tz":-540,"elapsed":3421,"user":{"displayName":"david song","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gil3Fx21Bq7GBVRGaEz4SijRJXcHDbCf-XMuKGf6Q=s64","userId":"03748752257933305700"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)\n","import sys\n","sys.path.append(\"/content/gdrive/My Drive/Colab Notebooks\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"bOQK28OYpl24","colab_type":"text"},"source":["## 1. 개요"]},{"cell_type":"markdown","metadata":{"id":"g-TAnRD-Z_Bk","colab_type":"text"},"source":["### 1-1. 생물학적인 뉴런"]},{"cell_type":"markdown","metadata":{"id":"tvbyXV8haYVj","colab_type":"text"},"source":["- 인간의 뇌 : 1000억 개가 넘는 신경세포 (뉴런) 가 100조 개 이상의 시냅스를 통해 병렬적으로 연결되어 있다.\n","- 각각의 뉴런은 수상돌기 (Dendrite) 를 통해 다른 뉴런에서 입력 신호를 받아서 축색돌기 (Axon)를 통해 다른 뉴런으로 신호를 내보낸다.\n","- 시냅스 (Synapse)는 뉴런과 뉴런을 연결하는 역할을 한다.\n","- 출력신호는 입력된 신호가 모여서 일정한 용량을 넘어설 때 일어난다.\n","- 즉, 신경세포는 시냅스를 거쳐 수상돌기 (dendrite)로 받아들인 외부의 전달물질을 세포체에 저장하다가, 자신의 용량을 넘어서면 축색돌기 (Axon)를 통해 외부의 전달물질을 내보낸다."]},{"cell_type":"markdown","metadata":{"id":"GSLtjH2obTyN","colab_type":"text"},"source":["![alt text](https://drive.google.com/uc?id=17mthmy_-LuJSaG9khYwru2XX253QfuAQ)"]},{"cell_type":"markdown","metadata":{"id":"Rxj_3NyEbnGP","colab_type":"text"},"source":["### 1-2. 인공신경망 뉴런"]},{"cell_type":"markdown","metadata":{"id":"o8WMYRAubpUk","colab_type":"text"},"source":["- 생물학적인 뉴런을 수학적으로 모델링한 것.\n","- 여러 입력값을 받아, 일정 수준이 넘어서면 활성화되어 출력값을 내보낸다."]},{"cell_type":"markdown","metadata":{"id":"KB-YdwEYcAj4","colab_type":"text"},"source":["![alt text](https://drive.google.com/uc?id=1wSkkZePc79G_z6Zcriiuy7qvMKq4OUfF)"]},{"cell_type":"markdown","metadata":{"id":"dmdSCJb3wwmW","colab_type":"text"},"source":["- x1, x2, x3: 뉴런의 수상돌기 (Dendrite) 역할\n","- 활성화 함수 또한 일정 값을 넘어서면 1, 그 이하는 0 값을 출력하기 위해 시그모이드 (Sigmoid function) 를 사용한다.\n","- Sigmoid Function은 활성화 함수로 많이 사용되었으며, 0.5 이상의 값은 1, 0.5 미만의 값은 0에 대응되도록 한다."]},{"cell_type":"markdown","metadata":{"id":"YPqwHI0g0lWi","colab_type":"text"},"source":["## 2. 동작"]},{"cell_type":"markdown","metadata":{"id":"SWAti6A6tXAL","colab_type":"text"},"source":["## 3. 종류"]},{"cell_type":"markdown","metadata":{"id":"ZjMvuFL_xwep","colab_type":"text"},"source":["![alt text](https://drive.google.com/uc?id=1WtVYzMpJ4rATY1U0mdHbmu3WiccKbAbF)\n","![alt text](https://drive.google.com/uc?id=1mPr_pWw4q1DijFjAznfj4e6Tua1rbt_d)"]},{"cell_type":"markdown","metadata":{"id":"BgL7nSjw8qrN","colab_type":"text"},"source":["### 3-1. Deep Feedforward Network (DFN)\n","\n","- 가장 기본적으로 이용되는 인공신경망\n","- 입력층, 은닉층, 출력층으로 구성.\n","- 입력되었던 데이터들의 정보는 저장되지 않음.\n","- 문제점: 입력 순서에 따라 데이터 간의 종속성이 존재하는 시계열 데이터를 처리하는 데 한계점이 존재한다."]},{"cell_type":"markdown","metadata":{"id":"IG9glxBlEvoS","colab_type":"text"},"source":["![alt text](https://drive.google.com/uc?id=1wMTQoiBFKEyT69nqC_eUJsNrq9c-GP8i)"]},{"cell_type":"markdown","metadata":{"id":"BK74NgLU8-tW","colab_type":"text"},"source":["### 3-2. Recurrent Neural Network (RNN)\n","- 시계열 데이터( EX. 문자열 및 센서 데이터) 와 같이 시간적으로 연속성이 있는 데이터 처리.\n","- 은닉층의 각 뉴런에 순환 (recurrent) 연결을 추가하여 이전 시간에 입력된 데이터에 대한 은닉층의 출력을 현재 시간의 데이터를 예측할 때 다시 은닉층 뉴런에 입력한다.\n","- 문제점: 오랜 시간에 걸쳐 경향성이 나타나는 데이터를 학습할 때 gradient가 비정상적으로 감소하거나 증가하는 vanishing / exploding gradient problem이 발생한다."]},{"cell_type":"markdown","metadata":{"id":"9BWsxeFvE0_-","colab_type":"text"},"source":["![alt text](https://drive.google.com/uc?id=1jhY30GQmVLCOnTLgW_pL1L995poD1bWH)"]},{"cell_type":"markdown","metadata":{"id":"Nbfuw5a19sci","colab_type":"text"},"source":["### 3-3. Long Short-Term Memory (LSTM)\n","- RNN에서 발생하는 vanishing / exploding gradient problem 해결하기 위해 제안.\n","- forget gate, input gate, output gate라는 새로운 요소를 은닉층의 각 뉴런에 추가.\n","- Forget gate: 과거의 정보를 어느정도 기억할지 결정한다. 과거의 정보와 현재 데이터를 입력받아 sigmoid 취한 뒤에 그 값을 과거의 정보에 곱한다.\n","- input gate: 현재의 정보를 기억하기 위해 만들어졌다.\n","- output gate: 과거의 정보와 현재 데이터를 이용하여 뉴런의 출력을 결정한다."]},{"cell_type":"markdown","metadata":{"id":"nxKOdaADE9BI","colab_type":"text"},"source":["![alt text](https://drive.google.com/uc?id=1MvkliW3PjrHdk5z4QQjZGV6SFGVDrr_j)"]},{"cell_type":"markdown","metadata":{"id":"WpmO5Tu_-Q5W","colab_type":"text"},"source":["### 3-4. Autoencoder\n","- 비지도 학습 (unsupervised learning)을 기반으로 학습된다.\n","- 입력층, 은닉층, 출력층을 거쳐 입력 데이터가 그대로 다시 출력되도록 동작한다.\n","- autoencoder는 은닉층의 출력을 이용하는 데 목적이 있다.\n","- Data compression: 은닉층 뉴런의 수를 입력층이나 출력층 뉴런의 수보다 작게 설정하기 때문에 은닉층의 출력은 입력 데이터에 대한 압축 데이터로 볼 수 있다.\n","- Latent representation: 은닉층은 그 자체로 입력 데이터를 잘 표현하기 위한 새로운 공간을 형성하기 때문에, 은닉층의 출력은 입력 데이터에 대한 latent representation으로 활용될 수 있다."]},{"cell_type":"markdown","metadata":{"id":"7z_bcFUXFDNf","colab_type":"text"},"source":["![alt text](https://drive.google.com/uc?id=1d-MvU4pSfyev4tGNZGXflX5JqvzvEZWr)"]},{"cell_type":"markdown","metadata":{"id":"7rfRJJ57_zZC","colab_type":"text"},"source":["### 3-5. Variational Autoencoder (VAE)\n","- 기존 Autoencoder 에 확률 개념을 추가한 모델.\n","- 입력 데이터의 확률 분포를 근사하기 위해 학습이 진행.\n","- 입력 데이터를 생성하는 확률 분포의 확률밀도함수를 학습한다. \n","- 이 과정에서 VAE는 계산 및 학습의 편의성, 범용성 등을 위해 입력 데이터의 확률 분포를 Gaussian이라고 가정한다.\n","- VAE는 Generative model로도 활용할 수 있다."]},{"cell_type":"markdown","metadata":{"id":"SPxG-KlxFMCV","colab_type":"text"},"source":["![alt text](https://drive.google.com/uc?id=1hYpUDAk2tLcOTaRpRfIfKyIoChMLmoEx)"]},{"cell_type":"markdown","metadata":{"id":"VmtmO_yMAP8Z","colab_type":"text"},"source":["### 3-6. Convolutional Neural Network (CNN)\n","- 뉴런들이 느슨하게 연결되어 있다.\n","- DFN 이나 RNN에 비해 학습해야 하는 가중치의 수가 적다.\n","- 학습 및 예측이 빠르다."]},{"cell_type":"markdown","metadata":{"id":"7bOuFuBhGHIn","colab_type":"text"},"source":["![alt text](https://drive.google.com/uc?id=1GCQ8CTnp9FO0ldBUhQijz4qBVqgQSMlu)"]},{"cell_type":"markdown","metadata":{"id":"BLOrmhZCyAmP","colab_type":"text"},"source":["## Reference\n","\n"]},{"cell_type":"markdown","metadata":{"id":"iqzbHNYid78y","colab_type":"text"},"source":["- https://brunch.co.kr/@gdhan/6\n","- https://untitledtblog.tistory.com/154"]}]}